{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuation of the previous model. \n",
    "## Major changes in this model:\n",
    "<ol> \n",
    "    <li> Performing the change of origin to make all the data values positive (change will be done in preprocessor script) </li>\n",
    "    \n",
    "    <li> Apply the Absolute Neural Network (bidirectional model) for this problem </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, I start with the utility cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used for processing:\n",
    "import cPickle as pickle # for pickling the processed data\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np # numerical computations\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# the boss of tensorflow frameworks\n",
    "import tensorflow as tf\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "LICENSE\n",
      "Models\n",
      "README.md\n",
      "Scripts\n",
      "submissions :D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "data_path = \"../Data\" # the data path\n",
    "base_model_path = \"../Models\"\n",
    "\n",
    "data_files = {\n",
    "    \"train\": os.path.join(data_path, \"train.csv\"),\n",
    "    \"test\": os.path.join(data_path, \"test.csv\")\n",
    "}\n",
    "\n",
    "base_model_path = '../Models'\n",
    "\n",
    "plug_and_play_data_file_path = os.path.join(data_path, \"plug_and_play_for_ANN.pickle\")\n",
    "\n",
    "# constants:\n",
    "(train_size, dev_size, test_size) = (0.9, 0.05, 0.05) # values are unit ratios\n",
    "no_of_features = 57\n",
    "no_of_itreations = 10000 \n",
    "batch_size = 512\n",
    "checkpoint_factor = 50\n",
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to unpickle the given file and load the obj back into the python environment\n",
    "def unPickleIt(pickle_path): # might throw the file not found exception\n",
    "    '''\n",
    "        function to unpickle the object from the given path\n",
    "        @param\n",
    "        pickle_path => the path where the pickle file is located\n",
    "        @return => the object extracted from the saved path\n",
    "    '''\n",
    "\n",
    "    with open(pickle_path, 'rb') as dumped_pickle:\n",
    "        obj = pickle.load(dumped_pickle)\n",
    "\n",
    "    return obj # return the unpickled object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data and create the train / dev / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = unPickleIt(plug_and_play_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data_dict['features']; Y = data_dict['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57, 595212), (1, 595212))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape # check if the shapes are compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep the variances for the features\n",
    "variances = data_dict['variances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to split the data into train, dev and test sets\n",
    "def train_dev_test_split_data(X, Y):\n",
    "    '''\n",
    "        function to split the X and Y arrays into train, dev and test sets\n",
    "        @param\n",
    "        X => the input features to train on\n",
    "        Y => the ideal labels for the given inputs\n",
    "        @return => train_X, train_Y, dev_X, dev_Y, test_X, test_Y: the names suggest meanings\n",
    "    '''\n",
    "    m_examples = X.shape[-1] # total number of examples to train on\n",
    "    \n",
    "    # first parition point\n",
    "    train_dev_partition_point = int((m_examples * train_size) + 0.5)\n",
    "    \n",
    "    # second partition point \n",
    "    dev_test_partition_point = train_dev_partition_point + int((m_examples * dev_size) + 0.5)\n",
    "    \n",
    "    ''' perform the actual split of the data '''\n",
    "    # Training set splitting:\n",
    "    train_X = X[:, : train_dev_partition_point]; train_Y = Y[:, : train_dev_partition_point]\n",
    "    \n",
    "    # dev set splitting\n",
    "    dev_X = X[:, train_dev_partition_point: dev_test_partition_point]\n",
    "    dev_Y = Y[:, train_dev_partition_point: dev_test_partition_point]\n",
    "    \n",
    "    # test set splitting\n",
    "    test_X = X[:, dev_test_partition_point:]; test_Y = Y[:, dev_test_partition_point:]\n",
    "    \n",
    "    # return the so formed splits\n",
    "    return train_X, train_Y, dev_X, dev_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, train_Y, dev_X, dev_Y, test_X, test_Y = train_dev_test_split_data(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X shape: (57, 535691)\n",
      "Training Y shape: (1, 535691)\n",
      "Dev X shape     : (57, 29761)\n",
      "Dev Y shape     : (1, 29761)\n",
      "Test X shape    : (57, 29760)\n",
      "Test Y shape    : (1, 29760)\n"
     ]
    }
   ],
   "source": [
    "# print the shapes of all the above obtained sets:\n",
    "print \"Training X shape: \" + str(train_X.shape)\n",
    "print \"Training Y shape: \" + str(train_Y.shape)\n",
    "print \"Dev X shape     : \" + str(dev_X.shape)\n",
    "print \"Dev Y shape     : \" + str(dev_Y.shape)\n",
    "print \"Test X shape    : \" + str(test_X.shape)\n",
    "print \"Test Y shape    : \" + str(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both the assertions pass!!\n"
     ]
    }
   ],
   "source": [
    "# Make sure that no Example has been left out\n",
    "assert X.shape[-1] == np.hstack((train_X, dev_X, test_X)).shape[-1], \"Examples have been left out\"\n",
    "assert Y.shape[-1] == np.hstack((train_Y, dev_Y, test_Y)).shape[-1], \"Labels have been left out\"\n",
    "\n",
    "# If both the above asserts are successful, we can go ahead and print the following statement\n",
    "print \"Both the assertions pass!!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cool! So now Let's get onto the part where we build the Tensorflow Graph\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "## I am going to keep the graph scoped and in a single cell, so that I can port it into the production graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the num_units in each layer of the feed_forward neural network\n",
    "layer_dims = [512, 512, 512, 512, 512, 512, 512, 512, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 535691)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this point to restart the graph building process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # scoped as Inputs\n",
    "with tf.variable_scope(\"Input\"):\n",
    "    # define the placeholders for the input data\n",
    "    # placeholder for feeding in input data batch\n",
    "    input_X = tf.placeholder(tf.float32, shape=(None, no_of_features), name=\"Input_features\")\n",
    "    labels_Y = tf.placeholder(tf.int32, shape=(None,), name=\"Ideal_labels\") # placeholder for the labels\n",
    "    one_hot_encoded_labels_Y = tf.one_hot(labels_Y, depth=2, axis=1, name=\"One_hot_label_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Input/One_hot_label_encoder:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_labels_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoped as model:\n",
    "with tf.variable_scope(\"Deep_Neural_Network\"):\n",
    "    # define the layers for the neural network.\n",
    "    with tf.name_scope(\"Encoder\"):\n",
    "        ''' This is The forward-backward neural network with abs activation function '''\n",
    "        # layer 1 => \n",
    "        fwd_lay1 = tf.layers.dense(input_X, layer_dims[0], activation=tf.abs, name=\"layer_1\")\n",
    "        # layer 2 =>\n",
    "        fwd_lay2 = tf.layers.dense(fwd_lay1, layer_dims[1], activation=tf.abs, name=\"layer_2\")\n",
    "        # layer 3 =>\n",
    "        fwd_lay3 = tf.layers.dense(fwd_lay2, layer_dims[2], activation=tf.abs, name=\"layer_3\")\n",
    "        # layer 4 =>\n",
    "        fwd_lay4 = tf.layers.dense(fwd_lay3, layer_dims[3], activation=tf.abs, name=\"layer_4\")\n",
    "        # layer 5 =>\n",
    "        fwd_lay5 = tf.layers.dense(fwd_lay4, layer_dims[4], activation=tf.abs, name=\"layer_5\")\n",
    "        # layer 6 =>\n",
    "        fwd_lay6 = tf.layers.dense(fwd_lay5, layer_dims[5], activation=tf.abs, name=\"layer_6\")\n",
    "        # layer 7 =>\n",
    "        fwd_lay7 = tf.layers.dense(fwd_lay6, layer_dims[6], activation=tf.abs, name=\"layer_7\")\n",
    "        # layer 8 =>\n",
    "        fwd_lay8 = tf.layers.dense(fwd_lay7, layer_dims[7], activation=tf.abs, name=\"layer_8\")\n",
    "        # layer 9 =>\n",
    "        fwd_lay9 = tf.layers.dense(fwd_lay8, layer_dims[8], activation=tf.abs, name=\"layer_9\")\n",
    "        \n",
    "    ''' Separately record all the activations as histograms '''\n",
    "    # recording the summaries to visualize separately\n",
    "    fwd_lay1_summary = tf.summary.histogram(\"fwd_lay1_summary\", fwd_lay1)\n",
    "    fwd_lay2_summary = tf.summary.histogram(\"fwd_lay2_summary\", fwd_lay2)\n",
    "    fwd_lay3_summary = tf.summary.histogram(\"fwd_lay3_summary\", fwd_lay3)\n",
    "    fwd_lay4_summary = tf.summary.histogram(\"fwd_lay4_summary\", fwd_lay4)\n",
    "    fwd_lay5_summary = tf.summary.histogram(\"fwd_lay5_summary\", fwd_lay5)\n",
    "    fwd_lay6_summary = tf.summary.histogram(\"fwd_lay6_summary\", fwd_lay6)\n",
    "    fwd_lay7_summary = tf.summary.histogram(\"fwd_lay7_summary\", fwd_lay7)\n",
    "    fwd_lay8_summary = tf.summary.histogram(\"fwd_lay8_summary\", fwd_lay8)\n",
    "    fwd_lay9_summary = tf.summary.histogram(\"fwd_lay9_summary\", fwd_lay9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"\", reuse=True):\n",
    "    # bring out all the weights from the network\n",
    "    lay_1_wts = tf.get_variable(\"Deep_Neural_Network/layer_1/kernel\")\n",
    "    lay_2_wts = tf.get_variable(\"Deep_Neural_Network/layer_2/kernel\")\n",
    "    lay_3_wts = tf.get_variable(\"Deep_Neural_Network/layer_3/kernel\")\n",
    "    lay_4_wts = tf.get_variable(\"Deep_Neural_Network/layer_4/kernel\")\n",
    "    lay_5_wts = tf.get_variable(\"Deep_Neural_Network/layer_5/kernel\")\n",
    "    lay_6_wts = tf.get_variable(\"Deep_Neural_Network/layer_6/kernel\")\n",
    "    lay_7_wts = tf.get_variable(\"Deep_Neural_Network/layer_7/kernel\")\n",
    "    lay_8_wts = tf.get_variable(\"Deep_Neural_Network/layer_8/kernel\")\n",
    "    lay_9_wts = tf.get_variable(\"Deep_Neural_Network/layer_9/kernel\")\n",
    "    \n",
    "    lay_1_biases = tf.get_variable(\"Deep_Neural_Network/layer_1/bias\")\n",
    "    lay_2_biases = tf.get_variable(\"Deep_Neural_Network/layer_2/bias\")\n",
    "    lay_3_biases = tf.get_variable(\"Deep_Neural_Network/layer_3/bias\")\n",
    "    lay_4_biases = tf.get_variable(\"Deep_Neural_Network/layer_4/bias\")\n",
    "    lay_5_biases = tf.get_variable(\"Deep_Neural_Network/layer_5/bias\")\n",
    "    lay_6_biases = tf.get_variable(\"Deep_Neural_Network/layer_6/bias\")\n",
    "    lay_7_biases = tf.get_variable(\"Deep_Neural_Network/layer_7/bias\")\n",
    "    lay_8_biases = tf.get_variable(\"Deep_Neural_Network/layer_8/bias\")\n",
    "    lay_9_biases = tf.get_variable(\"Deep_Neural_Network/layer_9/bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Deep_Neural_Network/layer_1/kernel:0' shape=(57, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Deep_Neural_Network/layer_8/kernel:0' shape=(512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'Deep_Neural_Network/layer_9/kernel:0' shape=(512, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Deep_Neural_Network/layer_1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Deep_Neural_Network/layer_8/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'Deep_Neural_Network/layer_9/bias:0' shape=(2,) dtype=float32_ref>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay_1_wts, lay_8_wts, lay_9_wts, lay_1_biases, lay_8_biases, lay_9_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Deep_Neural_Network/Encoder/layer_9/Abs:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_back_in = fwd_lay9\n",
    "y_back_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Decoder\"):\n",
    "        lay_0_biases = tf.get_variable(\"layer_0/bias\", shape=(no_of_features, ))\n",
    "    \n",
    "        # layer 1 => \n",
    "        bwd_lay1 = tf.abs(tf.matmul(y_back_in, tf.transpose(lay_9_wts)) + lay_8_biases)\n",
    "        # layer 2 => \n",
    "        bwd_lay2 = tf.abs(tf.matmul(bwd_lay1, tf.transpose(lay_8_wts)) + lay_7_biases)\n",
    "        # layer 3 => \n",
    "        bwd_lay3 = tf.abs(tf.matmul(bwd_lay2, tf.transpose(lay_7_wts)) + lay_6_biases)\n",
    "        # layer 4 => \n",
    "        bwd_lay4 = tf.abs(tf.matmul(bwd_lay3, tf.transpose(lay_6_wts)) + lay_5_biases)\n",
    "        # layer 5 => \n",
    "        bwd_lay5 = tf.abs(tf.matmul(bwd_lay4, tf.transpose(lay_5_wts)) + lay_4_biases)\n",
    "        # layer 6 => \n",
    "        bwd_lay6 = tf.abs(tf.matmul(bwd_lay5, tf.transpose(lay_4_wts)) + lay_3_biases)\n",
    "        # layer 7 => \n",
    "        bwd_lay7 = tf.abs(tf.matmul(bwd_lay6, tf.transpose(lay_3_wts)) + lay_2_biases)\n",
    "        # layer 8 => \n",
    "        bwd_lay8 = tf.abs(tf.matmul(bwd_lay7, tf.transpose(lay_2_wts)) + lay_1_biases)\n",
    "        # layer 9 => \n",
    "        bwd_lay9 = tf.abs(tf.matmul(bwd_lay8, tf.transpose(lay_1_wts)) + lay_0_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Decoder/Abs_8:0' shape=(?, 57) dtype=float32>,\n",
       " <tf.Tensor 'Input/Input_features:0' shape=(?, 57) dtype=float32>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_back_out = bwd_lay9\n",
    "x_back_out, input_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to compute the directional cosines of the input values\n",
    "def directional_cosines(X):\n",
    "    ''' \n",
    "        calculate the directional cosines of the inputs\n",
    "    '''\n",
    "    square = tf.square(X)\n",
    "    sum_square = tf.reduce_sum(square, axis=1, keep_dims=True)\n",
    "    dcs = X / tf.sqrt(sum_square)\n",
    "    \n",
    "    # return the directional cosines:\n",
    "    return dcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoped as predictions\n",
    "with tf.variable_scope(\"Prediction\"):\n",
    "    prediction = directional_cosines(y_back_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoped as loss\n",
    "with tf.variable_scope(\"Loss\"):\n",
    "    # define the forward loss\n",
    "    fwd_loss = tf.reduce_mean(tf.abs(prediction - one_hot_encoded_labels_Y))\n",
    "    \n",
    "    # define the reverse loss\n",
    "    rev_loss = tf.reduce_mean(tf.abs(x_back_out - input_X))\n",
    "    \n",
    "    total_loss = fwd_loss + rev_loss\n",
    "        \n",
    "    # record the loss summary:\n",
    "    tf.summary.scalar(\"Fwd_loss\", fwd_loss)\n",
    "    tf.summary.scalar(\"Bwd_loss\", rev_loss)\n",
    "    tf.summary.scalar(\"Tot_loss\", total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoped as train_step\n",
    "with tf.variable_scope(\"Train_Step\"):\n",
    "    # define the optimizer and the train_step:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr) # this has been manually tuned\n",
    "    train_step = optimizer.minimize(total_loss, name=\"train_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoped as init operation\n",
    "with tf.variable_scope(\"Init\"):\n",
    "    init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scoped as summaries\n",
    "with tf.variable_scope(\"Summary\"):\n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The graph has been defined. Now, use the session executer to run the graph and see how it trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Model2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to execute the session and train the model:\n",
    "def execute_graph(dataX, dataY, exec_graph, model_name, no_of_iterations):\n",
    "    '''\n",
    "        function to start and execute the session with training.\n",
    "        @param \n",
    "        dataX, dataY => the data to train on\n",
    "        exec_graph => the computation graph to be trained\n",
    "        model_name => the name of the model where the files will be saved\n",
    "        no_of_itreations => no of iterations for which the model needs to be trained\n",
    "        @return => Nothing, this function has a side effect\n",
    "    '''\n",
    "    assert dataX.shape[-1] == dataY.shape[-1], \"The Dimensions of input X and labels Y don't match\"\n",
    "    \n",
    "    # the number of examples in the dataset\n",
    "    no_of_examples = dataX.shape[-1]\n",
    "    \n",
    "    with tf.Session(graph=exec_graph) as sess:\n",
    "        # create the tensorboard writer for collecting summaries:\n",
    "        log_dir = os.path.join(base_model_path, model_name)\n",
    "        tensorboard_writer = tf.summary.FileWriter(logdir=log_dir, graph=sess.graph, filename_suffix=\".bot\")\n",
    "        \n",
    "        # The saver object for saving and loading the model\n",
    "        saver = tf.train.Saver(max_to_keep=2)\n",
    "        \n",
    "        # check if the model has been saved.\n",
    "        model_path = log_dir\n",
    "        model_file = os.path.join(model_path, model_name) # the name of the model is same as dir\n",
    "        if(os.path.isfile(os.path.join(base_model_path, model_name, \"checkpoint\"))):\n",
    "            # the model exists and you can restore the weights\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "        else:\n",
    "            # no saved model found. so, run the global variables initializer:\n",
    "            sess.run(init_op)\n",
    "\n",
    "        print \"Starting the training ...\"\n",
    "        print \"===============================================================================================\"\n",
    "        \n",
    "        batch_index = 0 # initialize it to 0\n",
    "        # start the training:\n",
    "        for iteration in range(no_of_itreations):\n",
    "            \n",
    "            # fetch the input and create the batch:\n",
    "            start = batch_index; end = start + batch_size\n",
    "            inp_X = dataX[:, start: end].T # extract the input features\n",
    "            inp_Y = dataY[:, start: end].T # extract the labels\n",
    "            \n",
    "            # feed the input to the graph and get the output:\n",
    "            _, cost = sess.run((train_step, total_loss), feed_dict={input_X: inp_X, labels_Y: np.squeeze(inp_Y)})\n",
    "            \n",
    "            # checkpoint the model at certain times\n",
    "            if((iteration + 1) % checkpoint_factor == 0):\n",
    "                # compute the summary:\n",
    "                summary = sess.run(all_summaries, feed_dict={input_X: inp_X, labels_Y: np.squeeze(inp_Y)})\n",
    "                \n",
    "                # accumulate the summary\n",
    "                tensorboard_writer.add_summary(summary, (iteration + 1))\n",
    "                \n",
    "                # print the cost at this point\n",
    "                print \"Iteration: \" + str(iteration + 1) + \" Current cost: \" + str(cost)\n",
    "                \n",
    "                # save the model trained so far:\n",
    "                saver.save(sess, model_file, global_step = (iteration + 1))\n",
    "                \n",
    "            # increment the batch_index\n",
    "            batch_index = (batch_index + batch_size) % no_of_examples\n",
    "            \n",
    "        print \"===============================================================================================\"\n",
    "        print \"Training complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Models/Model2/Model2-10000\n",
      "Starting the training ...\n",
      "===============================================================================================\n",
      "Iteration: 50 Current cost: 1.57684\n",
      "Iteration: 100 Current cost: 1.51471\n",
      "Iteration: 150 Current cost: 1.47866\n",
      "Iteration: 200 Current cost: 1.47617\n",
      "Iteration: 250 Current cost: 1.54763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5f483f2e2d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use the above defined method to start the training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexecute_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-924fb5068b87>\u001b[0m in \u001b[0;36mexecute_graph\u001b[0;34m(dataX, dataY, exec_graph, model_name, no_of_iterations)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# feed the input to the graph and get the output:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_X\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_Y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# checkpoint the model at certain times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use the above defined method to start the training:\n",
    "execute_graph(train_X, train_Y, tf.get_default_graph(), model_name, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the accuracy on the dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(dataX, dataY, exec_graph, model_name, threshold = 0.5):\n",
    "    '''\n",
    "        Function to run the trained model and calculate it's accuracy on the given inputs\n",
    "        @param \n",
    "        dataX, dataY => The data to be used for accuracy calculation\n",
    "        exec_graph => the Computation graph to be used\n",
    "        model_name => the model to restore the weights from\n",
    "        threshold => the accuracy threshold (by default it is 0.5)\n",
    "        @return => None (function has side effect)\n",
    "    '''\n",
    "    assert dataX.shape[-1] == dataY.shape[-1], \"The Dimensions of input X and labels Y don't match\"\n",
    "    \n",
    "    # the number of examples in the dataset\n",
    "    no_of_examples = dataX.shape[-1]\n",
    "    \n",
    "    with tf.Session(graph=exec_graph) as sess:\n",
    "        \n",
    "        # The saver object for saving and loading the model\n",
    "        saver = tf.train.Saver(max_to_keep=2)\n",
    "        \n",
    "        # the model must exist and you must be able to restore the weights\n",
    "        model_path = os.path.join(base_model_path, model_name)\n",
    "        assert os.path.isfile(os.path.join(model_path, \"checkpoint\")), \"Model doesn't exist\"\n",
    "        \n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "        \n",
    "        # compute the predictions given out by model\n",
    "        preds = sess.run(prediction, feed_dict={input_X: dataX.T, labels_Y: np.squeeze(dataY.T)})\n",
    "        print preds.shape\n",
    "        print preds[100: 120, :]\n",
    "        \n",
    "        label_preds = np.argmax(preds, axis=1)\n",
    "        \n",
    "        # calculate the accuracy in percentage:\n",
    "        correct = np.sum((label_preds == np.squeeze(dataY.T)))\n",
    "        accuracy = (float(correct) / dataX.shape[-1]) * 100 # for percentage\n",
    "        \n",
    "    # return the so calculated accuracy:\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Models/Model2/Model2-250\n",
      "Train_Set Accuracy: 96.3577883519\n"
     ]
    }
   ],
   "source": [
    "print \"Train_Set Accuracy: \" + str(calc_accuracy(train_X, train_Y, tf.get_default_graph(), model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../Models/Model2/Model2-250\n",
      "(29761, 2)\n",
      "[[  9.99999940e-01   3.78828554e-04]\n",
      " [  9.99999881e-01   5.06505254e-04]\n",
      " [  9.99999702e-01   7.19872944e-04]\n",
      " [  9.99999881e-01   5.46909811e-04]\n",
      " [  9.99999940e-01   5.23313705e-04]\n",
      " [  9.99999881e-01   5.81403612e-04]\n",
      " [  9.99999762e-01   5.95882651e-04]\n",
      " [  9.99999762e-01   6.16361445e-04]\n",
      " [  9.99999702e-01   6.75294083e-04]\n",
      " [  9.99999881e-01   5.61628898e-04]\n",
      " [  9.99999702e-01   7.40846037e-04]\n",
      " [  9.99999762e-01   6.18186488e-04]\n",
      " [  9.99999881e-01   5.81368862e-04]\n",
      " [  9.99999881e-01   4.78910340e-04]\n",
      " [  9.99999702e-01   7.98453984e-04]\n",
      " [  9.99999940e-01   5.36307925e-04]\n",
      " [  9.99999940e-01   2.76879437e-04]\n",
      " [  9.99999702e-01   6.59662590e-04]\n",
      " [  1.00000000e+00   2.58263899e-04]\n",
      " [  1.00000000e+00   3.17295926e-04]]\n",
      "Dev Set Accuracy: 96.3038876382\n"
     ]
    }
   ],
   "source": [
    "print \"Dev Set Accuracy: \" + str(calc_accuracy(dev_X, dev_Y, tf.get_default_graph(), model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model doesn't show any new promise, but the network has indeed been trained as per the forward-backward architecture. Let's see what happens now. (Although the accuracy results are just as they were earlier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
